{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8bc90a-c335-45ec-8aad-919b7993fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from RPA.Browser.Selenium import Selenium\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from time import sleep\n",
    "from robot.api import logger\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from utils import last_date_months, last_date\n",
    "from get_infos import get_infos\n",
    "\n",
    "# Search term\n",
    "search_term = \"billion dollar\"\n",
    "sections = ['Books', 'Business']\n",
    "months = 0\n",
    "\n",
    "# Open the NY Times search page and search for the term\n",
    "browser = Selenium()\n",
    "browser.open_available_browser(\"https://www.nytimes.com\")\n",
    "\n",
    "#reject terms\n",
    "reject_button_xpath = \"xpath://button[@data-testid='Reject all-btn']\"\n",
    "browser.wait_until_element_is_visible(reject_button_xpath)\n",
    "sleep(1)\n",
    "browser.click_button(reject_button_xpath)\n",
    "\n",
    "#search term\n",
    "search_button_xpath = \"xpath://button[@data-testid='search-button']\"\n",
    "browser.wait_until_element_is_enabled(search_button_xpath)\n",
    "browser.click_button(search_button_xpath)\n",
    "\n",
    "search_input_xpath = \"xpath://input[@data-testid='search-input']\"\n",
    "browser.wait_until_element_is_enabled(search_input_xpath)\n",
    "browser.input_text(search_input_xpath, search_term)\n",
    "browser.press_keys(search_input_xpath, \"ENTER\")\n",
    "\n",
    "#click in section\n",
    "section_button_xpath = \"xpath://div[@data-testid='section']//button\"\n",
    "browser.wait_until_element_is_enabled(section_button_xpath)\n",
    "browser.click_button(section_button_xpath)\n",
    "\n",
    "#choose section\n",
    "for section in sections:\n",
    "    section_xpath = f\"xpath:*//ul[@data-testid='multi-select-dropdown-list']//li//label//span[contains(text(), '{section}')]\"\n",
    "    try:\n",
    "        browser.click_element(section_xpath)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to choose section {section}. erro {e}\")\n",
    "        \n",
    "#choose Newest news\n",
    "newest_news_xpath = \"xpath://option[contains(text(), 'Sort by Newest')]\"\n",
    "browser.click_element(newest_news_xpath)\n",
    "\n",
    "sleep(1)\n",
    "\n",
    "#show all the news in the range of months\n",
    "for x in range(200):\n",
    "    last_date_value = last_date(browser)\n",
    "    if isinstance(last_date_value, bool):\n",
    "        last_date_value = last_date_months(months) + timedelta(days=1)\n",
    "    if last_date_months(months) < last_date_value:\n",
    "        show_more_xpath = \"xpath://button[@data-testid='search-show-more-button']\"\n",
    "        browser.wait_until_element_is_visible(show_more_xpath)\n",
    "        browser.scroll_element_into_view(show_more_xpath)\n",
    "        if browser.is_element_visible(show_more_xpath):\n",
    "            browser.click_button(show_more_xpath)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "        \n",
    "df_infos = get_infos(browser, search_term, months)\n",
    "\n",
    "download_images(browser, df_infos)\n",
    "\n",
    "df_infos.drop('image_src', axis=1, inplace=True)\n",
    "df_infos.to_excel(\"nyt_news_info.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da6e41-8e7e-499d-b1b6-5c14d7d27ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b453339-ec1d-4785-a05b-4490c4175656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4026befd-fb02-4d3a-8be4-c816835fd86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting data from the news\n",
    "\n",
    "def extract_from_news(browser):\n",
    "    list_news_xpath = \"xpath://ol[@data-testid='search-results']//li\"\n",
    "    current_year = datetime.now().year\n",
    "    aux = 1\n",
    "\n",
    "    news_dict = {\n",
    "        \"title\":[],\n",
    "        \"date\":[],\n",
    "        \"description\":[],\n",
    "        \"picture_filename\":[],\n",
    "        \"amount_search_phrases\":[],\n",
    "        \"amount_of_money\":[],\n",
    "        \"image_src\":[],\n",
    "        \"image_filename\":[]\n",
    "    }\n",
    "\n",
    "    for x in browser.find_elements(list_news_xpath):\n",
    "        news_html = x.get_attribute(\"outerHTML\")\n",
    "        if re.search(r'SKIP ADVERTISEMENT', news_html):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            date = x.text\n",
    "            data_str = re.search(r\".*\\n\", date).group(0).replace(\"\\n\", \"\")\n",
    "            if 'ago' in data_str:\n",
    "                time_ago = int(re.search(r'(\\d+)(m|h) ago', data_str).group(1))\n",
    "                if re.search(r'(\\d+)(m|h) ago', data_str).group(2) == \"m\":\n",
    "                    data_obj = datetime.now() - timedelta(minutes=time_ago)\n",
    "                else:\n",
    "                    data_obj = datetime.now() - timedelta(hours=time_ago)\n",
    "            else:\n",
    "                try:\n",
    "                    data_obj = datetime.strptime(data_str, \"%b. %d, %Y\")\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        complete_date_str = f\"{data_str}, {current_year}\"\n",
    "                        data_obj = datetime.strptime(complete_date_str, \"%b. %d, %Y\")\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Failed to load this News. erro {e}\")\n",
    "\n",
    "            if last_date_months(months) > data_obj:\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load this News. Erro: {e}\")\n",
    "\n",
    "\n",
    "        title = re.search(r'<h4.*?>(.*?)<\\/h4>', news_html).group(1)\n",
    "        description = re.search(r'<\\/h4><p.*?>(.*?)<\\/p>', news_html).group(1)\n",
    "        try:\n",
    "            image_name =  re.search(r'<img alt=\"(.*?)\"', news_html).group(1)\n",
    "            if image_name == \"\":\n",
    "                image_name = \"image_name_not_found\"\n",
    "        except Exception as e:\n",
    "            image_name = \"image_name_not_found\"\n",
    "            logger.error(f\"Image name not found. Erro: {e}\")\n",
    "\n",
    "        try:\n",
    "            src_image =  re.search(r'src=\"(.*?)\"', news_html).group(1)\n",
    "        except AttributeError:\n",
    "            src_image = \"link_not_found\"\n",
    "\n",
    "\n",
    "        phrase_to_count = title + description\n",
    "        phrase_to_count = phrase_to_count.lower()\n",
    "        count_search_phrase = phrase_to_count.count(search_term.lower())\n",
    "        regex_coin = re.compile(r'\\$(\\d+\\.\\d+|\\d+(,\\d+)*(\\.\\d+)?)|(\\d+)\\s*dollars|\\d+\\s*USD')\n",
    "        amount_money = bool(re.search(regex_coin, phrase_to_count))\n",
    "\n",
    "\n",
    "\n",
    "        # print(title)\n",
    "        # print(data_str)\n",
    "        # print(description)\n",
    "        # print(image_name)\n",
    "        # print(src_image)\n",
    "        # print(count_search_phrase)\n",
    "        # print(amount_money)\n",
    "        # print(\"-----------------------------\")\n",
    "\n",
    "\n",
    "        news_dict['title'].append(title)\n",
    "        news_dict['date'].append(data_str)\n",
    "        news_dict['description'].append(description)\n",
    "        news_dict['picture_filename'].append(image_name)\n",
    "        news_dict['amount_search_phrases'].append(count_search_phrase)\n",
    "        news_dict['amount_of_money'].append(amount_money)\n",
    "        news_dict['image_src'].append(src_image)\n",
    "        news_dict['image_filename'].append(f\"image_{aux}\")\n",
    "        aux +=1\n",
    "\n",
    "    news_information = pd.DataFrame(news_dict)\n",
    "\n",
    "    return news_information\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49855a8b-4882-4968-b5b1-7f0a3ac69b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7abd1e-2f85-4f88-b8de-9f57925d7d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_images(browser, df_infos):\n",
    "    df_imagens = df_infos[['image_src','image_filename']]\n",
    "    pictures_dir = \"pictures\"\n",
    "    \n",
    "    if not os.path.exists(pictures_dir):\n",
    "        os.makedirs(pictures_dir)\n",
    "        \n",
    "    for index, row in df_imagens.iterrows():\n",
    "        try:\n",
    "            browser.go_to(row['image_src'])\n",
    "            image_path = f\"pictures/{(row['image_filename'])}.png\"\n",
    "            browser.capture_element_screenshot(\"tag:img\",image_path)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save image: {row['image_filename']}. Error: {e}\") \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa08d8d-c3ad-4a8b-b254-3e58b2c3ddf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f401acb-8266-46b1-81c0-b85b82d91d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a5f0d-d1a2-4ea1-a07e-6d7983d7340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7254a27b-f948-4f78-89b2-01660bd796e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.request(\"post\", \"https://cloud.robocorp.com/api/v1/workspaces/699152e3-4b14-405e-9129-8247d2c9df1b/work-items\", headers={\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": \"RC-WSKEY {api_key}\"\n",
    "}, json={\"process\":{\"id\":\"nyt_news\"},\"payload\":{\n",
    "         \"search_term\": \"billion dollar\",\n",
    "         \"sections\": ['Books', 'Business'],\n",
    "         \"months\": 0\n",
    "      }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4574b6-2a7e-4c7b-8439-08a0bea0fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.request(\"post\", \"https://cloud.robocorp.com/api/v1/workspaces/699152e3-4b14-405e-9129-8247d2c9df1b/work-items/{work_item_id}/files\", headers={\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": \"RC-WSKEY 5pPO5FNjfpnCtLAG1LBB7F7cz3a9lH3K0Wfk0Uzdr0i6JhoY9BFQcNmqFVnlqJHfyoJjt1Nq0sCxXbzPyIE6wtMEFWiG5ikyTlQU1WopSaSbx9vsKA29kdt1S1ImFR6j\"\n",
    "}, json={\"file_name\":\"work_items\",\"file_size\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61a6a72-ab4c-4eec-af4e-06b758077e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
